{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imutils\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "# to compute angles\n",
    "from math import atan2, cos, sin, sqrt, pi\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "from skimage.filters import threshold_local\n",
    "import tensorflow as tf\n",
    "from skimage import measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_plate(self, plate):\n",
    " \n",
    "    gray = cv2.cvtColor(plate, cv2.COLOR_BGR2GRAY)\n",
    "    thresh = cv2.adaptiveThreshold(gray, 255,\n",
    "                                   cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                   cv2.THRESH_BINARY, 11, 2)\n",
    "     \n",
    "    contours, _ = cv2.findContours(thresh.copy(),\n",
    "                                      cv2.RETR_EXTERNAL,\n",
    "                                      cv2.CHAIN_APPROX_NONE)\n",
    " \n",
    "    if contours:\n",
    "         \n",
    "        areas = [cv2.contourArea(c) for c in contours]\n",
    "         \n",
    "        # index of the largest contour in the\n",
    "        # areas array\n",
    "        max_index = np.argmax(areas) \n",
    " \n",
    "        max_cnt = contours[max_index]\n",
    "        max_cntArea = areas[max_index]\n",
    "        x, y, w, h = cv2.boundingRect(max_cnt)\n",
    " \n",
    "        if not self.ratioCheck(max_cntArea,\n",
    "                               plate.shape[1],\n",
    "                               plate.shape[0]):\n",
    "            return plate, False, None\n",
    "         \n",
    "        return plate, True, [x, y, w, h]\n",
    "     \n",
    "    else:\n",
    "        return plate, False, None\n",
    "    \n",
    "def ratioCheck(self, area, width, height):\n",
    "     \n",
    "    min = self.min_area\n",
    "    max = self.max_area\n",
    " \n",
    "    ratioMin = 3\n",
    "    ratioMax = 6\n",
    " \n",
    "    ratio = float(width) / float(height)\n",
    "     \n",
    "    if ratio < 1:\n",
    "        ratio = 1 / ratio\n",
    " \n",
    "    if (area < min or area > max) or (ratio < ratioMin or ratio > ratioMax):\n",
    "        return False\n",
    "     \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_cont(character_contours):\n",
    "\t\"\"\"\n",
    "\tTo sort contours\n",
    "\t\"\"\"\n",
    "\ti = 0\n",
    "\tboundingBoxes = [cv2.boundingRect(c) for c in character_contours]\n",
    "\t\n",
    "\t(character_contours, boundingBoxes) = zip(*sorted(zip(character_contours,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\tboundingBoxes),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tkey = lambda b: b[1][i],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\treverse = False))\n",
    "\t\n",
    "\treturn character_contours\n",
    "\n",
    "\n",
    "def segment_chars(plate_img, fixed_width):\n",
    "\t\n",
    "\t\"\"\"\n",
    "\textract Value channel from the HSV format\n",
    "\tof image and apply adaptive thresholding\n",
    "\tto reveal the characters on the license plate\n",
    "\t\"\"\"\n",
    "\tV = cv2.split(cv2.cvtColor(plate_img, cv2.COLOR_BGR2HSV))[2]\n",
    "\n",
    "\tthresh = cv2.adaptiveThreshold(V, 255,\n",
    "\t\t\t\t\t\t\t\tcv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "\t\t\t\t\t\t\t\tcv2.THRESH_BINARY,\n",
    "\t\t\t\t\t\t\t\t11, 2)\n",
    "\n",
    "\tthresh = cv2.bitwise_not(thresh)\n",
    "\n",
    "\t# resize the license plate region to\n",
    "\t# a canoncial size\n",
    "\tplate_img = imutils.resize(plate_img, width = fixed_width)\n",
    "\tthresh = imutils.resize(thresh, width = fixed_width)\n",
    "\tbgr_thresh = cv2.cvtColor(thresh, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "\t# perform a connected components analysis\n",
    "\t# and initialize the mask to store the locations\n",
    "\t# of the character candidates\n",
    "\tlabels = measure.label(thresh, background = 0)\n",
    "\n",
    "\tcharCandidates = np.zeros(thresh.shape, dtype ='uint8')\n",
    "\n",
    "\t# loop over the unique components\n",
    "\tcharacters = []\n",
    "\tfor label in np.unique(labels):\n",
    "\t\t\n",
    "\t\t# if this is the background label, ignore it\n",
    "\t\tif label == 0:\n",
    "\t\t\tcontinue\n",
    "\t\t# otherwise, construct the label mask to display\n",
    "\t\t# only connected components for the current label,\n",
    "\t\t# then find contours in the label mask\n",
    "\t\tlabelMask = np.zeros(thresh.shape, dtype ='uint8')\n",
    "\t\tlabelMask[labels == label] = 255\n",
    "\n",
    "\t\tcnts = cv2.findContours(labelMask,\n",
    "\t\t\t\t\tcv2.RETR_EXTERNAL,\n",
    "\t\t\t\t\tcv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\t\tcnts = cnts[0]\n",
    "\n",
    "\t\t# ensure at least one contour was found in the mask\n",
    "\t\tif len(cnts) > 0:\n",
    "\n",
    "\t\t\t# grab the largest contour which corresponds\n",
    "\t\t\t# to the component in the mask, then grab the\n",
    "\t\t\t# bounding box for the contour\n",
    "\t\t\tc = max(cnts, key = cv2.contourArea)\n",
    "\t\t\t(boxX, boxY, boxW, boxH) = cv2.boundingRect(c)\n",
    "\n",
    "\t\t\t# compute the aspect ratio, solodity, and\n",
    "\t\t\t# height ration for the component\n",
    "\t\t\taspectRatio = boxW / float(boxH)\n",
    "\t\t\tsolidity = cv2.contourArea(c) / float(boxW * boxH)\n",
    "\t\t\theightRatio = boxH / float(plate_img.shape[0])\n",
    "\n",
    "\t\t\t# determine if the aspect ratio, solidity,\n",
    "\t\t\t# and height of the contour pass the rules\n",
    "\t\t\t# tests\n",
    "\t\t\tkeepAspectRatio = aspectRatio < 1.0\n",
    "\t\t\tkeepSolidity = solidity > 0.15\n",
    "\t\t\tkeepHeight = heightRatio > 0.5 and heightRatio < 0.95\n",
    "\n",
    "\t\t\t# check to see if the component passes\n",
    "\t\t\t# all the tests\n",
    "\t\t\tif keepAspectRatio and keepSolidity and keepHeight and boxW > 14:\n",
    "\t\t\t\t\n",
    "\t\t\t\t# compute the convex hull of the contour\n",
    "\t\t\t\t# and draw it on the character candidates\n",
    "\t\t\t\t# mask\n",
    "\t\t\t\thull = cv2.convexHull(c)\n",
    "\n",
    "\t\t\t\tcv2.drawContours(charCandidates, [hull], -1, 255, -1)\n",
    "\n",
    "\tcontours, hier = cv2.findContours(charCandidates,\n",
    "\t\t\t\t\t\t\t\t\t\tcv2.RETR_EXTERNAL,\n",
    "\t\t\t\t\t\t\t\t\t\tcv2.CHAIN_APPROX_SIMPLE)\n",
    "\t\n",
    "\tif contours:\n",
    "\t\tcontours = sort_cont(contours)\n",
    "\t\t\n",
    "\t\t# value to be added to each dimension\n",
    "\t\t# of the character\n",
    "\t\taddPixel = 4\n",
    "\t\tfor c in contours:\n",
    "\t\t\t(x, y, w, h) = cv2.boundingRect(c)\n",
    "\t\t\tif y > addPixel:\n",
    "\t\t\t\ty = y - addPixel\n",
    "\t\t\telse:\n",
    "\t\t\t\ty = 0\n",
    "\t\t\tif x > addPixel:\n",
    "\t\t\t\tx = x - addPixel\n",
    "\t\t\telse:\n",
    "\t\t\t\tx = 0\n",
    "\t\t\ttemp = bgr_thresh[y:y + h + (addPixel * 2),\n",
    "\t\t\t\t\t\t\tx:x + w + (addPixel * 2)]\n",
    "\n",
    "\t\t\tcharacters.append(temp)\n",
    "\t\t\t\n",
    "\t\treturn characters\n",
    "\t\n",
    "\telse:\n",
    "\t\treturn None\n",
    "\n",
    "class PlateFinder:\n",
    "\tdef __init__(self):\n",
    "\t\t\n",
    "\t\t# minimum area of the plate\n",
    "\t\tself.min_area = 4500\n",
    "\t\t\n",
    "\t\t# maximum area of the plate\n",
    "\t\tself.max_area = 30000\n",
    "\n",
    "\t\tself.element_structure = cv2.getStructuringElement(\n",
    "\t\t\t\t\t\t\tshape = cv2.MORPH_RECT, ksize =(22, 3))\n",
    "\n",
    "\tdef preprocess(self, input_img):\n",
    "\t\t\n",
    "\t\timgBlurred = cv2.GaussianBlur(input_img, (7, 7), 0)\n",
    "\t\t\n",
    "\t\t# convert to gray\n",
    "\t\tgray = cv2.cvtColor(imgBlurred, cv2.COLOR_BGR2GRAY)\n",
    "\t\t\n",
    "\t\t# sobelX to get the vertical edges\n",
    "\t\tsobelx = cv2.Sobel(gray, cv2.CV_8U, 1, 0, ksize = 3)\n",
    "\t\t\n",
    "\t\t# otsu's thresholding\n",
    "\t\tret2, threshold_img = cv2.threshold(sobelx, 0, 255,\n",
    "\t\t\t\t\t\tcv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "\t\telement = self.element_structure\n",
    "\t\tmorph_n_thresholded_img = threshold_img.copy()\n",
    "\t\tcv2.morphologyEx(src = threshold_img,\n",
    "\t\t\t\t\t\top = cv2.MORPH_CLOSE,\n",
    "\t\t\t\t\t\tkernel = element,\n",
    "\t\t\t\t\t\tdst = morph_n_thresholded_img)\n",
    "\t\t\n",
    "\t\treturn morph_n_thresholded_img\n",
    "\n",
    "\tdef extract_contours(self, after_preprocess):\n",
    "\t\t\n",
    "\t\tcontours, _ = cv2.findContours(after_preprocess,\n",
    "\t\t\t\t\t\t\t\t\t\tmode = cv2.RETR_EXTERNAL,\n",
    "\t\t\t\t\t\t\t\t\t\tmethod = cv2.CHAIN_APPROX_NONE)\n",
    "\t\treturn contours\n",
    "\n",
    "\tdef clean_plate(self, plate):\n",
    "\t\t\n",
    "\t\tgray = cv2.cvtColor(plate, cv2.COLOR_BGR2GRAY)\n",
    "\t\tthresh = cv2.adaptiveThreshold(gray,\n",
    "\t\t\t\t\t\t\t\t\t255,\n",
    "\t\t\t\t\t\t\t\t\tcv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "\t\t\t\t\t\t\t\t\tcv2.THRESH_BINARY,\n",
    "\t\t\t\t\t\t\t\t\t11, 2)\n",
    "\t\t\n",
    "\t\tcontours, _ = cv2.findContours(thresh.copy(),\n",
    "\t\t\t\t\t\t\t\t\t\tcv2.RETR_EXTERNAL,\n",
    "\t\t\t\t\t\t\t\t\t\tcv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "\t\tif contours:\n",
    "\t\t\tareas = [cv2.contourArea(c) for c in contours]\n",
    "\t\t\t\n",
    "\t\t\t# index of the largest contour in the area\n",
    "\t\t\t# array\n",
    "\t\t\tmax_index = np.argmax(areas)\n",
    "\n",
    "\t\t\tmax_cnt = contours[max_index]\n",
    "\t\t\tmax_cntArea = areas[max_index]\n",
    "\t\t\tx, y, w, h = cv2.boundingRect(max_cnt)\n",
    "\t\t\trect = cv2.minAreaRect(max_cnt)\n",
    "\t\t\t\n",
    "\t\t\tif not self.ratioCheck(max_cntArea, plate.shape[1],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tplate.shape[0]):\n",
    "\t\t\t\treturn plate, False, None\n",
    "\t\t\t\n",
    "\t\t\treturn plate, True, [x, y, w, h]\n",
    "\t\t\n",
    "\t\telse:\n",
    "\t\t\treturn plate, False, None\n",
    "\n",
    "\n",
    "\n",
    "\tdef check_plate(self, input_img, contour):\n",
    "\t\t\n",
    "\t\tmin_rect = cv2.minAreaRect(contour)\n",
    "\t\t\n",
    "\t\tif self.validateRatio(min_rect):\n",
    "\t\t\tx, y, w, h = cv2.boundingRect(contour)\n",
    "\t\t\tafter_validation_img = input_img[y:y + h, x:x + w]\n",
    "\t\t\tafter_clean_plate_img, plateFound, coordinates = self.clean_plate(\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\tafter_validation_img)\n",
    "\t\t\t\n",
    "\t\t\tif plateFound:\n",
    "\t\t\t\tcharacters_on_plate = self.find_characters_on_plate(\n",
    "\t\t\t\t\t\t\t\t\t\t\tafter_clean_plate_img)\n",
    "\t\t\t\t\n",
    "\t\t\t\tif (characters_on_plate is not None and len(characters_on_plate) == 8):\n",
    "\t\t\t\t\tx1, y1, w1, h1 = coordinates\n",
    "\t\t\t\t\tcoordinates = x1 + x, y1 + y\n",
    "\t\t\t\t\tafter_check_plate_img = after_clean_plate_img\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\treturn after_check_plate_img, characters_on_plate, coordinates\n",
    "\t\t\n",
    "\t\treturn None, None, None\n",
    "\n",
    "\tdef find_possible_plates(self, input_img):\n",
    "\t\t\n",
    "\t\t\"\"\"\n",
    "\t\tFinding all possible contours that can be plates\n",
    "\t\t\"\"\"\n",
    "\t\tplates = []\n",
    "\t\tself.char_on_plate = []\n",
    "\t\tself.corresponding_area = []\n",
    "\n",
    "\t\tself.after_preprocess = self.preprocess(input_img)\n",
    "\t\tpossible_plate_contours = self.extract_contours(self.after_preprocess)\n",
    "\n",
    "\t\tfor cnts in possible_plate_contours:\n",
    "\t\t\tplate, characters_on_plate, coordinates = self.check_plate(input_img, cnts)\n",
    "\t\t\t\n",
    "\t\t\tif plate is not None:\n",
    "\t\t\t\tplates.append(plate)\n",
    "\t\t\t\tself.char_on_plate.append(characters_on_plate)\n",
    "\t\t\t\tself.corresponding_area.append(coordinates)\n",
    "\n",
    "\t\tif (len(plates) > 0):\n",
    "\t\t\treturn plates\n",
    "\t\t\n",
    "\t\telse:\n",
    "\t\t\treturn None\n",
    "\n",
    "\tdef find_characters_on_plate(self, plate):\n",
    "\n",
    "\t\tcharactersFound = segment_chars(plate, 400)\n",
    "\t\tif charactersFound:\n",
    "\t\t\treturn charactersFound\n",
    "\n",
    "\t# PLATE FEATURES\n",
    "\tdef ratioCheck(self, area, width, height):\n",
    "\t\t\n",
    "\t\tmin = self.min_area\n",
    "\t\tmax = self.max_area\n",
    "\n",
    "\t\tratioMin = 3\n",
    "\t\tratioMax = 6\n",
    "\n",
    "\t\tratio = float(width) / float(height)\n",
    "\t\t\n",
    "\t\tif ratio < 1:\n",
    "\t\t\tratio = 1 / ratio\n",
    "\t\t\n",
    "\t\tif (area < min or area > max) or (ratio < ratioMin or ratio > ratioMax):\n",
    "\t\t\treturn False\n",
    "\t\t\n",
    "\t\treturn True\n",
    "\n",
    "\tdef preRatioCheck(self, area, width, height):\n",
    "\t\t\n",
    "\t\tmin = self.min_area\n",
    "\t\tmax = self.max_area\n",
    "\n",
    "\t\tratioMin = 2.5\n",
    "\t\tratioMax = 7\n",
    "\n",
    "\t\tratio = float(width) / float(height)\n",
    "\t\t\n",
    "\t\tif ratio < 1:\n",
    "\t\t\tratio = 1 / ratio\n",
    "\n",
    "\t\tif (area < min or area > max) or (ratio < ratioMin or ratio > ratioMax):\n",
    "\t\t\treturn False\n",
    "\t\t\n",
    "\t\treturn True\n",
    "\n",
    "\tdef validateRatio(self, rect):\n",
    "\t\t(x, y), (width, height), rect_angle = rect\n",
    "\n",
    "\t\tif (width > height):\n",
    "\t\t\tangle = -rect_angle\n",
    "\t\telse:\n",
    "\t\t\tangle = 90 + rect_angle\n",
    "\n",
    "\t\tif angle > 15:\n",
    "\t\t\treturn False\n",
    "\t\t\n",
    "\t\tif (height == 0 or width == 0):\n",
    "\t\t\treturn False\n",
    "\n",
    "\t\tarea = width * height\n",
    "\t\t\n",
    "\t\tif not self.preRatioCheck(area, width, height):\n",
    "\t\t\treturn False\n",
    "\t\telse:\n",
    "\t\t\treturn True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OCR:\n",
    "     \n",
    "    def __init__(self):\n",
    "         \n",
    "        self.model_file = \"model/binary_128_0.50_ver3.pb\"\n",
    "        self.label_file = \"model/binary_128_0.50_labels_ver2.txt\"\n",
    "        self.label = self.load_label(self.label_file)\n",
    "        self.graph = self.load_graph(self.model_file)\n",
    "        self.sess = tf.compat.v1.Session(graph = self.graph)\n",
    " \n",
    "    def load_graph(self, modelFile):\n",
    "         \n",
    "        graph = tf.Graph()\n",
    "        graph_def = tf.compat.v1.GraphDef()\n",
    "         \n",
    "        with open(modelFile, \"rb\") as f:\n",
    "            graph_def.ParseFromString(f.read())\n",
    "         \n",
    "        with graph.as_default():\n",
    "            tf.import_graph_def(graph_def)\n",
    "         \n",
    "        return graph\n",
    " \n",
    "    def load_label(self, labelFile):\n",
    "        label = []\n",
    "        proto_as_ascii_lines = tf.io.gfile.GFile(labelFile).readlines()\n",
    "         \n",
    "        for l in proto_as_ascii_lines:\n",
    "            label.append(l.rstrip())\n",
    "         \n",
    "        return label\n",
    " \n",
    "    def convert_tensor(self, image, imageSizeOuput):\n",
    "        \"\"\"\n",
    "        takes an image and transform it in tensor\n",
    "        \"\"\"\n",
    "        image = cv2.resize(image,\n",
    "                           dsize =(imageSizeOuput,\n",
    "                                  imageSizeOuput),\n",
    "                           interpolation = cv2.INTER_CUBIC)\n",
    "         \n",
    "        np_image_data = np.asarray(image)\n",
    "        np_image_data = cv2.normalize(np_image_data.astype('float'),\n",
    "                                      None, -0.5, .5,\n",
    "                                      cv2.NORM_MINMAX)\n",
    "         \n",
    "        np_final = np.expand_dims(np_image_data, axis = 0)\n",
    "         \n",
    "        return np_final\n",
    " \n",
    "    def label_image(self, tensor):\n",
    " \n",
    "        input_name = \"import/input\"\n",
    "        output_name = \"import/final_result\"\n",
    " \n",
    "        input_operation = self.graph.get_operation_by_name(input_name)\n",
    "        output_operation = self.graph.get_operation_by_name(output_name)\n",
    " \n",
    "        results = self.sess.run(output_operation.outputs[0],\n",
    "                                {input_operation.outputs[0]: tensor})\n",
    "        results = np.squeeze(results)\n",
    "        labels = self.label\n",
    "        top = results.argsort()[-1:][::-1]\n",
    "         \n",
    "        return labels[top[0]]\n",
    " \n",
    "    def label_image_list(self, listImages, imageSizeOuput):\n",
    "        plate = \"\"\n",
    "         \n",
    "        for img in listImages:\n",
    "             \n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                break\n",
    "            plate = plate + self.label_image(self.convert_tensor(img, imageSizeOuput))\n",
    "         \n",
    "        return plate, len(plate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29A39185\n",
      "29A33185\n",
      "29A33185\n",
      "29A39185\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-41e685449071>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mpossible_plates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfindPlate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_possible_plates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpossible_plates\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-f2042b601199>\u001b[0m in \u001b[0;36mfind_possible_plates\u001b[1;34m(self, input_img)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mcnts\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossible_plate_contours\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m                         \u001b[0mplate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcharacters_on_plate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoordinates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_plate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcnts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mplate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-f2042b601199>\u001b[0m in \u001b[0;36mcheck_plate\u001b[1;34m(self, input_img, contour)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mplateFound\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m \t\t\t\tcharacters_on_plate = self.find_characters_on_plate(\n\u001b[0m\u001b[0;32m    217\u001b[0m \t\t\t\t\t\t\t\t\t\t\tafter_clean_plate_img)\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-f2042b601199>\u001b[0m in \u001b[0;36mfind_characters_on_plate\u001b[1;34m(self, plate)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfind_characters_on_plate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m                 \u001b[0mcharactersFound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msegment_chars\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m400\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mcharactersFound\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m                         \u001b[1;32mreturn\u001b[0m \u001b[0mcharactersFound\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-f2042b601199>\u001b[0m in \u001b[0;36msegment_chars\u001b[1;34m(plate_img, fixed_width)\u001b[0m\n\u001b[0;32m     54\u001b[0m                 \u001b[1;31m# then find contours in the label mask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m                 \u001b[0mlabelMask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthresh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m'uint8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m                 \u001b[0mlabelMask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabels\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \t\tcnts = cv2.findContours(labelMask,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "findPlate = PlateFinder()\n",
    "model = OCR()\n",
    "\n",
    "cap = cv2.VideoCapture('video.MOV')\n",
    "\n",
    "while (cap.isOpened()):\n",
    "    ret, img = cap.read()\n",
    "\n",
    "    if ret == True:\n",
    "        cv2.imshow('original video', img)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        possible_plates = findPlate.find_possible_plates(img)\n",
    "\n",
    "        if possible_plates is not None:\n",
    "\n",
    "            for i, p in enumerate(possible_plates):\n",
    "                chars_on_plate = findPlate.char_on_plate[i]\n",
    "                recognized_plate, _ = model.label_image_list(\n",
    "                           chars_on_plate, imageSizeOuput = 128)\n",
    "\n",
    "                print(recognized_plate)\n",
    "                cv2.imshow('plate', p)\n",
    "                cv2.waitKey(0)\n",
    "                cv2.destroyAllWindows()\n",
    "\n",
    "                if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                    break\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No contour detected\n",
      "No contour detected\n",
      "No contour detected\n",
      "No contour detected\n",
      "No contour detected\n",
      "No contour detected\n",
      "No contour detected\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(1, 20):\n",
    "\n",
    "    img    = cv2.imread(f\"archive/images/Cars{i}.png\")\n",
    "    # cv2.imshow('HelloWorld', img)\n",
    "    grey = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.bilateralFilter(grey, 13, 15, 15) \n",
    "\n",
    "    edged = cv2.Canny(gray, 30, 200) \n",
    "    contours = cv2.findContours(edged.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = imutils.grab_contours(contours)\n",
    "    contours = sorted(contours, key = cv2.contourArea, reverse = True)[:10]\n",
    "    screenCnt = None\n",
    "\n",
    "\n",
    "    for c in contours:\n",
    "        \n",
    "        peri = cv2.arcLength(c, True)\n",
    "        approx = cv2.approxPolyDP(c, 0.018 * peri, True)\n",
    "\n",
    "        if len(approx) == 4:\n",
    "            screenCnt = approx\n",
    "            break\n",
    "\n",
    "    if screenCnt is None:\n",
    "        detected = 0\n",
    "        print (\"No contour detected\")\n",
    "        continue\n",
    "        \n",
    "    else:\n",
    "        detected = 1\n",
    "\n",
    "    if detected == 1:\n",
    "        cv2.drawContours(img, [screenCnt], -1, (0, 0, 255), 3)\n",
    "\n",
    "    mask = np.zeros(gray.shape,np.uint8)\n",
    "    new_image = cv2.drawContours(mask,[screenCnt],0,255,-1,)\n",
    "    new_image = cv2.bitwise_and(img,img,mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "cap = cv2.VideoCapture('Traffic_Camera.avi')\n",
    "\n",
    "frameRate = cap.get(5) #frame rate\n",
    "\n",
    "x=1\n",
    "while(cap.isOpened()):\n",
    "    frameId = cap.get(1) #current frame number\n",
    "    ret, frame = cap.read()\n",
    "    if (ret != True):\n",
    "        break\n",
    "    if (frameId % math.floor(frameRate) == 0):\n",
    "        filename = './test_images/image' +  str(int(x)) + \".jpg\";x+=1\n",
    "        cv2.imwrite(filename, frame)\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "programming_fever's License Plate Recognition\n",
      "\n",
      "Detected license plate Number is: \f",
      "\n",
      "programming_fever's License Plate Recognition\n",
      "\n",
      "Detected license plate Number is: \f",
      "\n",
      "programming_fever's License Plate Recognition\n",
      "\n",
      "Detected license plate Number is: \f",
      "\n",
      "programming_fever's License Plate Recognition\n",
      "\n",
      "Detected license plate Number is: \f",
      "\n",
      "programming_fever's License Plate Recognition\n",
      "\n",
      "Detected license plate Number is: \f",
      "\n",
      "programming_fever's License Plate Recognition\n",
      "\n",
      "Detected license plate Number is: \f",
      "\n",
      "programming_fever's License Plate Recognition\n",
      "\n",
      "Detected license plate Number is: \f",
      "\n",
      "programming_fever's License Plate Recognition\n",
      "\n",
      "Detected license plate Number is: \f",
      "\n",
      "programming_fever's License Plate Recognition\n",
      "\n",
      "Detected license plate Number is: \f",
      "\n",
      "programming_fever's License Plate Recognition\n",
      "\n",
      "Detected license plate Number is: \f",
      "\n",
      "programming_fever's License Plate Recognition\n",
      "\n",
      "Detected license plate Number is: \f",
      "\n",
      "programming_fever's License Plate Recognition\n",
      "\n",
      "Detected license plate Number is: \f",
      "\n",
      "programming_fever's License Plate Recognition\n",
      "\n",
      "Detected license plate Number is: \f",
      "\n",
      "programming_fever's License Plate Recognition\n",
      "\n",
      "Detected license plate Number is: \f",
      "\n",
      "programming_fever's License Plate Recognition\n",
      "\n",
      "Detected license plate Number is: \f",
      "\n",
      "programming_fever's License Plate Recognition\n",
      "\n",
      "Detected license plate Number is: \f",
      "\n",
      "programming_fever's License Plate Recognition\n",
      "\n",
      "Detected license plate Number is: \f",
      "\n",
      "programming_fever's License Plate Recognition\n",
      "\n",
      "Detected license plate Number is: \f",
      "\n",
      "programming_fever's License Plate Recognition\n",
      "\n",
      "Detected license plate Number is: \f",
      "\n",
      "programming_fever's License Plate Recognition\n",
      "\n",
      "Detected license plate Number is: \f",
      "\n",
      "programming_fever's License Plate Recognition\n",
      "\n",
      "Detected license plate Number is: \f",
      "\n",
      "programming_fever's License Plate Recognition\n",
      "\n",
      "Detected license plate Number is: \f",
      "\n",
      "programming_fever's License Plate Recognition\n",
      "\n",
      "Detected license plate Number is: \f",
      "\n",
      "programming_fever's License Plate Recognition\n",
      "\n",
      "Detected license plate Number is: \f",
      "\n",
      "programming_fever's License Plate Recognition\n",
      "\n",
      "Detected license plate Number is: \f",
      "\n",
      "programming_fever's License Plate Recognition\n",
      "\n",
      "Detected license plate Number is: \f",
      "\n",
      "programming_fever's License Plate Recognition\n",
      "\n",
      "Detected license plate Number is: \f",
      "\n",
      "programming_fever's License Plate Recognition\n",
      "\n",
      "Detected license plate Number is: \f",
      "\n",
      "programming_fever's License Plate Recognition\n",
      "\n",
      "Detected license plate Number is: \f",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 30):\n",
    "\n",
    "    img = cv2.imread(f\"test_images/image{i}.jpg\")\n",
    "    y=0\n",
    "    x=1400\n",
    "    h=700\n",
    "    w=500\n",
    "    img = img[y:y+h, x:x+w]\n",
    "#     cv2.imshow('car',img)\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "    grey = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.bilateralFilter(grey, 13, 15, 15) \n",
    "\n",
    "    edged = cv2.Canny(gray, 30, 200) \n",
    "    contours = cv2.findContours(edged.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = imutils.grab_contours(contours)\n",
    "    contours = sorted(contours, key = cv2.contourArea, reverse = True)[:10]\n",
    "    screenCnt = None\n",
    "\n",
    "    for c in contours:\n",
    "        \n",
    "        peri = cv2.arcLength(c, True)\n",
    "        approx = cv2.approxPolyDP(c, 0.018 * peri, True)\n",
    "\n",
    "        if len(approx) == 4:\n",
    "            screenCnt = approx\n",
    "            break\n",
    "\n",
    "    if screenCnt is None:\n",
    "        detected = 0\n",
    "        print (\"No contour detected\")\n",
    "        continue\n",
    "        \n",
    "    else:\n",
    "        detected = 1\n",
    "\n",
    "    if detected == 1:\n",
    "        cv2.drawContours(img, [screenCnt], -1, (0, 0, 255), 3)\n",
    "\n",
    "    mask = np.zeros(gray.shape,np.uint8)\n",
    "    new_image = cv2.drawContours(mask,[screenCnt],0,255,-1,)\n",
    "    new_image = cv2.bitwise_and(img,img,mask=mask)\n",
    "    (x, y) = np.where(mask == 255)\n",
    "    (topx, topy) = (np.min(x), np.min(y))\n",
    "    (bottomx, bottomy) = (np.max(x), np.max(y))\n",
    "    Cropped = gray[topx:bottomx+1, topy:bottomy+1]\n",
    "\n",
    "    text = pytesseract.image_to_string(Cropped)\n",
    "    print(\"programming_fever's License Plate Recognition\\n\")\n",
    "    print(\"Detected license plate Number is:\",text)\n",
    "    img = cv2.resize(img,(500,700))\n",
    "    Cropped = cv2.resize(Cropped,(400,200))\n",
    "#     cv2.imshow('car',img)\n",
    "#     cv2.imshow('Cropped',Cropped)\n",
    "\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_axis(img, p_, q_, colour, scale):\n",
    "    p = list(p_)\n",
    "    q = list(q_)\n",
    "    angle = atan2(p[1] - q[1], p[0] - q[0]) # angle in radians\n",
    "    hypotenuse = sqrt((p[1] - q[1]) * (p[1] - q[1]) + (p[0] - q[0]) * (p[0] - q[0]))\n",
    "    # Here we lengthen the arrow by a factor of scale\n",
    "    q[0] = p[0] - scale * hypotenuse * cos(angle)\n",
    "    q[1] = p[1] - scale * hypotenuse * sin(angle)\n",
    "    cv2.line(img, (int(p[0]), int(p[1])), (int(q[0]), int(q[1])), colour, 1, cv2.LINE_AA)\n",
    "    # create the arrow hooks\n",
    "    p[0] = q[0] + 9 * cos(angle + pi / 4)\n",
    "    p[1] = q[1] + 9 * sin(angle + pi / 4)\n",
    "    cv2.line(img, (int(p[0]), int(p[1])), (int(q[0]), int(q[1])), colour, 1, cv2.LINE_AA)\n",
    "    p[0] = q[0] + 9 * cos(angle - pi / 4)\n",
    "    p[1] = q[1] + 9 * sin(angle - pi / 4)\n",
    "    cv2.line(img, (int(p[0]), int(p[1])), (int(q[0]), int(q[1])), colour, 1, cv2.LINE_AA)\n",
    "    \n",
    "def get_orientation(pts, img):\n",
    "    sz = len(pts)\n",
    "    data_pts = np.empty((sz, 2), dtype=np.float64)\n",
    "    for i in range(data_pts.shape[0]):\n",
    "        data_pts[i,0] = pts[i,0,0]\n",
    "        data_pts[i,1] = pts[i,0,1]\n",
    "    # Perform PCA analysis\n",
    "    mean = np.empty((0))\n",
    "    mean, eigenvectors, eigenvalues = cv2.PCACompute2(data_pts, mean)\n",
    "    # Store the center of the object\n",
    "    cntr = (int(mean[0,0]), int(mean[0,1]))\n",
    "    cv2.circle(img, cntr, 3, (255, 0, 255), 2)\n",
    "    p1 = (cntr[0] + 0.02 * eigenvectors[0,0] * eigenvalues[0,0], cntr[1] + 0.02 *  eigenvectors[0,1] * eigenvalues[0,0])\n",
    "    p2 = (cntr[0] - 0.02 * eigenvectors[1,0] * eigenvalues[1,0], cntr[1] - 0.02 * eigenvectors[1,1] * eigenvalues[1,0])\n",
    "    draw_axis(img, cntr, p1, (0, 150, 0), 1)\n",
    "    draw_axis(img, cntr, p2, (200, 150, 0), 5)\n",
    "    angle = atan2(eigenvectors[0,1], eigenvectors[0,0]) # orientation in radians\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in contours:\n",
    "    \n",
    "    peri = cv2.arcLength(c, True)\n",
    "    approx = cv2.approxPolyDP(c, 0.018 * peri, True)\n",
    "\n",
    "    if len(approx) == 4:\n",
    "        screenCnt = approx\n",
    "        break\n",
    "\n",
    "\n",
    "if screenCnt is None:\n",
    "    detected = 0\n",
    "    print (\"No contour detected\")\n",
    "    \n",
    "    \n",
    "else:\n",
    "    detected = 1\n",
    "\n",
    "if detected == 1:\n",
    "    cv2.drawContours(img, [screenCnt], -1, (0, 0, 255), 3)\n",
    "\n",
    "get_orientation(c,img)\n",
    "cv2.imshow('frame',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9d62803a1cbd2182104a1183605f86308b1943107a6ea7d89939a22c783e6f48"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
