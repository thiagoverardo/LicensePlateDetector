{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detector e leitor de placas de carro\n",
    "\n",
    "### Manuela Castilla e Thiago Verardo\n",
    "\n",
    "### Objetivo:\n",
    "\n",
    "Este projeto tem como objetivo a criação de um modelo capaz de identificar e ler uma placa de carro através de um vídeo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import atan2, cos, sin, sqrt, pi\n",
    "import cv2\n",
    "import imutils\n",
    "import pytesseract\n",
    "from skimage.segmentation import clear_border\n",
    "\n",
    "# Passar o path para SEU pytesseract \n",
    " pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "# pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files (x86)\\Tesseract-OCR\\tesseract.exe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando as funções de reconhecimento da orientação do veículo (3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_axis(img, p_, q_, colour, scale):\n",
    "    p = list(p_)\n",
    "    q = list(q_)\n",
    "    angle = atan2(p[1] - q[1], p[0] - q[0]) # radianos\n",
    "    hypotenuse = sqrt((p[1] - q[1]) * (p[1] - q[1]) + (p[0] - q[0]) * (p[0] - q[0]))\n",
    "    # realizamos a escala das setas\n",
    "    q[0] = p[0] - scale * hypotenuse * cos(angle)\n",
    "    q[1] = p[1] - scale * hypotenuse * sin(angle)\n",
    "    cv2.line(img, (int(p[0]), int(p[1])), (int(q[0]), int(q[1])), colour, 1, cv2.LINE_AA)\n",
    "    \n",
    "    # novas setas\n",
    "    p[0] = q[0] + 9 * cos(angle + pi / 4)\n",
    "    p[1] = q[1] + 9 * sin(angle + pi / 4)\n",
    "    cv2.line(img, (int(p[0]), int(p[1])), (int(q[0]), int(q[1])), colour, 1, cv2.LINE_AA)\n",
    "    p[0] = q[0] + 9 * cos(angle - pi / 4)\n",
    "    p[1] = q[1] + 9 * sin(angle - pi / 4)\n",
    "    cv2.line(img, (int(p[0]), int(p[1])), (int(q[0]), int(q[1])), colour, 1, cv2.LINE_AA)\n",
    "    \n",
    "def get_orientation(pts, img):\n",
    "    sz = len(pts)\n",
    "    data_pts = np.empty((sz, 2), dtype=np.float64)\n",
    "    for i in range(data_pts.shape[0]):\n",
    "        data_pts[i,0] = pts[i,0,0]\n",
    "        data_pts[i,1] = pts[i,0,1]\n",
    "        \n",
    "    # analise PCA\n",
    "    mean = np.empty((0))\n",
    "    mean, eigenvectors, eigenvalues = cv2.PCACompute2(data_pts, mean)\n",
    "    \n",
    "    # guarda o centro do objeto analisado\n",
    "    cntr = (int(mean[0,0]), int(mean[0,1]))\n",
    "    cv2.circle(img, cntr, 3, (255, 0, 255), 2)\n",
    "    p1 = (cntr[0] + 0.02 * eigenvectors[0,0] * eigenvalues[0,0], cntr[1] + 0.02 *  eigenvectors[0,1] * eigenvalues[0,0])\n",
    "    p2 = (cntr[0] - 0.02 * eigenvectors[1,0] * eigenvalues[1,0], cntr[1] - 0.02 * eigenvectors[1,1] * eigenvalues[1,0])\n",
    "    draw_axis(img, cntr, p1, (0, 150, 0), 1)\n",
    "    draw_axis(img, cntr, p2, (200, 150, 0), 5)\n",
    "    angle = atan2(eigenvectors[0,1], eigenvectors[0,0]) # orientation in radians\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformando o video (video.MOV) em frames para poderem ser analisados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "cap = cv2.VideoCapture('video.MOV')\n",
    "\n",
    "frameRate = cap.get(5) #frame rate\n",
    "\n",
    "x=1\n",
    "while(cap.isOpened()):\n",
    "    frameId = cap.get(1) #frame atual\n",
    "    ret, frame = cap.read()\n",
    "    if (ret != True):\n",
    "        break\n",
    "    if (frameId % math.floor(frameRate) == 0):\n",
    "        filename = './videoPics/image' +  str(int(x)) + \".jpg\";x+=1\n",
    "        cv2.imwrite(filename, frame)\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando a funções para a detecção da placa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tratamento_imagem_deteccao_ret(img):\n",
    "    grey = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # determinar as partes mais escuras com background claro\n",
    "    rectKern = cv2.getStructuringElement(cv2.MORPH_RECT, (13, 5))\n",
    "    blackhat = cv2.morphologyEx(grey, cv2.MORPH_BLACKHAT, rectKern)\n",
    "\n",
    "    # fecha onde ha poucas partes escuras para encontrar a parte clara maior\n",
    "    squareKern = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    light = cv2.morphologyEx(grey, cv2.MORPH_CLOSE, squareKern)\n",
    "    light = cv2.threshold(light, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "\n",
    "    # Calculo do gradX a partir do blackhat\n",
    "    gradX = cv2.Sobel(blackhat, ddepth=cv2.CV_32F, dx=1, dy=0, ksize=-1)\n",
    "    gradX = np.absolute(gradX)\n",
    "    (minVal, maxVal) = (np.min(gradX), np.max(gradX))\n",
    "    gradX = 255 * ((gradX - minVal) / (maxVal - minVal))\n",
    "    gradX = gradX.astype(\"uint8\")\n",
    "    \n",
    "    # Aplicando blurr, fechamento da imagem e threshold para\n",
    "    # obtermos a representação do gradiente (metodo Otsu)\n",
    "    gradX = cv2.GaussianBlur(gradX, (5, 5), 0)\n",
    "    gradX = cv2.morphologyEx(gradX, cv2.MORPH_CLOSE, rectKern)\n",
    "    thresh = cv2.threshold(gradX, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "    \n",
    "    # Limpando a imagem com erosão e dilatação\n",
    "    thresh = cv2.erode(thresh, None, iterations=2)\n",
    "    thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "    \n",
    "    # realizando um AND bit a bit com a parte clara da imagem\n",
    "    thresh = cv2.bitwise_and(thresh, thresh, mask=light)\n",
    "    thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "    thresh = cv2.erode(thresh, None, iterations=1)\n",
    "\n",
    "    # Encontrando os contornos e devolvendo sortidos e apenas os maiores (prováveis placas)\n",
    "    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    cnts = sorted(cnts, key=cv2.contourArea, reverse=True)[:5]\n",
    "    \n",
    "    \n",
    "    return cnts, grey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def license_detection(cnts, grey):\n",
    "    # inicialização de variáveis\n",
    "    lpCnt = None\n",
    "    roi = None\n",
    "    minAR = 4\n",
    "    maxAR = 6\n",
    "    clearBorder = False\n",
    "    # percorrendo os candidatos para placa\n",
    "    ar_list = []\n",
    "    lp = None\n",
    "    for c in cnts:\n",
    "        # Pegando a proporção do candidato\n",
    "        (x, y, w, h) = cv2.boundingRect(c)\n",
    "        ar = w / float(h)\n",
    "        if ar >= minAR and ar <= maxAR:\n",
    "        # Guardando o contorno da placa\n",
    "            lpCnt = c\n",
    "            lp = grey[y:y + h, x:x + w]\n",
    "            roi = cv2.threshold(lp, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "            # Checando se ainda precisa limpar algum ruído\n",
    "            if clearBorder:\n",
    "                roi = clear_border(roi)\n",
    "            # Pegando a orientação do veículo a partir da função criada anteriormente\n",
    "            get_orientation(c,img)\n",
    "            break\n",
    "    \n",
    "    return roi, lp, x, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando as variáveis para o tesseract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passando os parametros para o Tesseract\n",
    "alphanumeric = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\"\n",
    "options = \"-c tessedit_char_whitelist={}\".format(alphanumeric)\n",
    "options += \" --psm {}\".format(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rodando as funções com as imagens capturadas do vídeo desejado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_test_list = []\n",
    "conta = 0\n",
    "for i in range(29):\n",
    "    \n",
    "    # Percorrendo todas as imagens do vídeo para identificar placas e orientação\n",
    "    img = cv2.imread(f\"videoPics/image{i+1}.jpg\")\n",
    "    cnts, grey = tratamento_imagem_deteccao_ret(img)\n",
    "    roi, licensePlate, x, y = license_detection(cnts, grey)\n",
    "    \n",
    "    # Inicializando o texto\n",
    "    lpText = None\n",
    "    if roi is not None:\n",
    "        lpText = pytesseract.image_to_string(licensePlate, config=options)\n",
    "        if lpText not in lp_test_list:\n",
    "            lp_test_list.append(lpText)\n",
    "            newstr = lpText.rstrip()\n",
    "            \n",
    "            # Colocando o texto identificado na imagem final\n",
    "            cv2.putText(img, str(lpText[:-2]), (x + 20, y - 15), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 0), lineType=cv2.LINE_AA, thickness=4)\n",
    "            cv2.putText(img, str(lpText[:-2]), (x + 20, y - 15), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255, 20, 0), lineType=cv2.LINE_AA, thickness=2)\n",
    "            \n",
    "            # Salvando tanto a imagem final, quanto a placamidentificada (para checar o que está errado, caso esteja)\n",
    "            filename = f\"./resultado/total{conta}.jpg\"\n",
    "            cv2.imwrite(filename, img)\n",
    "            filename = f\"./resultado/placa{conta}.jpg\"\n",
    "            conta += 1\n",
    "            cv2.imwrite(filename, licensePlate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referências\n",
    "- https://analyticsindiamag.com/detecting-orientation-of-objects-in-image-using-pca-and-opencv/\n",
    "\n",
    "- https://www.pyimagesearch.com/2020/09/21/opencv-automatic-license-number-plate-recognition-anpr-with-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
